<!DOCTYPE html>
<html lang="en"><head>
<script src="ftorch_workshop_slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="ftorch_workshop_slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="ftorch_workshop_slides_files/libs/quarto-html/popper.min.js"></script>
<script src="ftorch_workshop_slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="ftorch_workshop_slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ftorch_workshop_slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="ftorch_workshop_slides_files/libs/quarto-html/quarto-syntax-highlighting-dark-732fb9ccd080a018ca85ca5d15770f52.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="ftorch_workshop_slides_files/libs/quarto-contrib/qrcodejs-v1.0.0/qrcode.js"></script>
<link href="ftorch_workshop_slides_files/libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="ftorch_workshop_slides_files/libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.31">

  <meta name="dcterms.date" content="2025-06-02">
  <title>Coupling Machine Learning to Fortran using the FTorch Library</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="ftorch_workshop_slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="ftorch_workshop_slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #97947a;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #97947a;  padding-left: 4px; }
    div.sourceCode
      { color: #f8f8f2; background-color: #2b2b2b; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #f8f8f2; } /* Normal */
    code span.al { color: #dcc6e0; } /* Alert */
    code span.an { color: #d4d0ab; } /* Annotation */
    code span.at { color: #ffd700; } /* Attribute */
    code span.bn { color: #dcc6e0; } /* BaseN */
    code span.bu { color: #f5ab35; } /* BuiltIn */
    code span.cf { color: #ffa07a; } /* ControlFlow */
    code span.ch { color: #abe338; } /* Char */
    code span.cn { color: #ffa07a; } /* Constant */
    code span.co { color: #d4d0ab; } /* Comment */
    code span.cv { color: #d4d0ab; font-style: italic; } /* CommentVar */
    code span.do { color: #d4d0ab; font-style: italic; } /* Documentation */
    code span.dt { color: #dcc6e0; } /* DataType */
    code span.dv { color: #dcc6e0; } /* DecVal */
    code span.er { color: #dcc6e0; } /* Error */
    code span.ex { color: #ffd700; } /* Extension */
    code span.fl { color: #f5ab35; } /* Float */
    code span.fu { color: #ffd700; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #d4d0ab; } /* Information */
    code span.kw { color: #ffa07a; } /* Keyword */
    code span.op { color: #00e0e0; } /* Operator */
    code span.ot { color: #ffa07a; } /* Other */
    code span.pp { color: #dcc6e0; } /* Preprocessor */
    code span.sc { color: #00e0e0; } /* SpecialChar */
    code span.ss { color: #abe338; } /* SpecialString */
    code span.st { color: #abe338; } /* String */
    code span.va { color: #f5ab35; } /* Variable */
    code span.vs { color: #abe338; } /* VerbatimString */
    code span.wa { color: #d4d0ab; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="ftorch_workshop_slides_files/libs/revealjs/dist/theme/quarto-fbe9041449a4f797356ea399dbbc0222.css">
  <link href="ftorch_workshop_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="ftorch_workshop_slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="ftorch_workshop_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="ftorch_workshop_slides_files/libs/revealjs/plugin/reveal-attribution/attribution.css" rel="stylesheet">
  <link href="ftorch_workshop_slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Coupling Machine Learning to Fortran using the FTorch Library</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Jack Atkinson <a href="https://orcid.org/0000-0001-5001-4812" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
        <p class="quarto-title-affiliation">
            Senior Research Software Engineer <br> ICCS - University of Cambridge
          </p>
    </div>
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Joe Wallwork <a href="https://orcid.org/0000-0002-3646-091X" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
        <p class="quarto-title-affiliation">
            Research Software Engineer <br> ICCS - University of Cambridge
          </p>
    </div>
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Tom Meltzer <a href="https://orcid.org/0000-0003-1740-9550" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
        <p class="quarto-title-affiliation">
            Senior Research Software Engineer <br> ICCS - University of Cambridge
          </p>
    </div>
<div class="quarto-title-author">
<div class="quarto-title-author-name">
The ICCS Team and Collaborators 
</div>
</div>
</div>

  <p class="date">2025-06-02</p>
</section>
<section id="precursors" class="slide level2 smaller nostretch">
<h2>Precursors</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h4 id="slides-and-materials">Slides and Materials</h4>
<!-- TODO: Update link to slides -->
<p>To access links or follow on your own device these slides can be found at: <a href="https://cambridge-iccs.github.io/FTorch-workshop">cambridge-iccs.github.io/FTorch-workshop</a></p>
<div style="text-align: center">
<div id="qr7dekity9" class="qrcode"></div>
<script type="text/javascript">
var qrcode = new QRCode("qr7dekity9", {"colorDark":"#000000","colorLight":"#ffffff","height":"200","text":"https://jackatkinson.net/slides","width":"200"});
</script>
    
</div>
</div><div class="column" style="width:50%;">
<h4 id="licensing">Licensing</h4>
<p>Except where otherwise noted, these presentation materials are licensed under the Creative Commons <a href="https://creativecommons.org/licenses/by-nc/4.0/legalcode">Attribution-NonCommercial 4.0 International</a> (<a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>) License.</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc.eu.svg" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
<p>Vectors and icons by <a href="https://www.svgrepo.com">SVG Repo</a> under <a href="https://creativecommons.org/publicdomain/zero/1.0/deed.en">CC0(1.0)</a> or <a href="https://fontawesome.com/">FontAwesome</a> under <a href="http://scripts.sil.org/OFL">SIL OFL 1.1</a></p>
</div></div>
<!-- =============================================================================== -->
</section>
<section>
<section id="preparation" class="title-slide slide level1 center">
<h1>Preparation</h1>

</section>
<section id="codespaces" class="slide level2">
<h2>Codespaces</h2>
<p>In this tutorial, we will be using GitHub Codespaces to run the exercises. If you are not familiar with Codespaces, please refer to the <a href="https://docs.github.com/en/codespaces">Codespaces documentation</a> for more information.</p>
<div class="fragment">
<ol type="1">
<li>Navigate to the <a href="https://github.com/Cambridge-ICCS/FTorch-workshop">FTorch-workshop repo page</a> repository and click on the green “Code” button.</li>
<li>Select “Codespaces” and then “Create codespace on main”.</li>
<li>Wait for the codespace to be created and opened in your browser. You will be put in a VSCode environment with a terminal at the bottom.</li>
</ol>
</div>
<div class="fragment">
<p>Note that we have set up the codespace to have a Python virtual environment set up and activated for you.</p>
</div>
<div class="fragment">
<p>Execute the following to start the FTorch build process:</p>
<pre class="shell"><code>source build_FTorch.sh</code></pre>
</div>
</section>
<section id="exercise-0-hello-fortran-and-pytorch" class="slide level2">
<h2>Exercise 0 – Hello Fortran and PyTorch!</h2>
<div class="fragment">
<p><strong>Question:</strong> What are people’s experience levels with and use cases of Fortran and PyTorch?</p>
</div>
<p><br>
</p>
<div class="fragment">
<p>Navigate to <code>exercises/exercise_00/</code> where you will see both Python and Fortran files.</p>
</div>
</section>
<section id="python" class="slide level2">
<h2>Python</h2>
<p><code>pytorch_net.py</code> defines a net <code>SimpleNet</code> that takes an input vector of length 5 and multiplies it by 2.</p>
<p>Note:</p>
<ul>
<li>the <code>nn.Module</code> class</li>
<li>the <code>forward()</code> method</li>
</ul>
<p>Running:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb2-1"><a href="" aria-hidden="true" tabindex="-1"></a>python pytorch_net.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>should produce the output:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb3-1"><a href="" aria-hidden="true" tabindex="-1"></a>Input is  tensor([0., 1., 2., 3., 4.]).</span>
<span id="cb3-2"><a href="" aria-hidden="true" tabindex="-1"></a>Output is tensor([0., 2., 4., 6., 8.]).</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="compilers-and-cmake" class="slide level2">
<h2>Compilers and CMake</h2>
<p>First we will check that we have Fortran, C and C++ compilers installed:</p>
<p>Running:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb4-1"><a href="" aria-hidden="true" tabindex="-1"></a>gfortran --version</span>
<span id="cb4-2"><a href="" aria-hidden="true" tabindex="-1"></a>gcc --version</span>
<span id="cb4-3"><a href="" aria-hidden="true" tabindex="-1"></a>g++ --version</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="columns">
<div class="column" style="width:60%;">
<p>Should produce output similar to:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb5-1"><a href="" aria-hidden="true" tabindex="-1"></a>GNU Fortran (Homebrew GCC 14.1.0_1) 14.1.0</span>
<span id="cb5-2"><a href="" aria-hidden="true" tabindex="-1"></a>Copyright (C) 2024 Free Software Foundation, Inc.</span>
<span id="cb5-3"><a href="" aria-hidden="true" tabindex="-1"></a>This is free software; see the source for copying conditions.</span>
<span id="cb5-4"><a href="" aria-hidden="true" tabindex="-1"></a>There is NO warranty; not even for MERCHANTABILITY or</span>
<span id="cb5-5"><a href="" aria-hidden="true" tabindex="-1"></a>FITNESS FOR A PARTICULAR PURPOSE.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="width:40%;">
<p>and not:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb6-1"><a href="" aria-hidden="true" tabindex="-1"></a>bash: command not found: gfortran</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div>
<p><br>
</p>
<div class="fragment">
<div class="columns">
<div class="column" style="width:60%;">
<p>Later on we will also need CMake.</p>
</div><div class="column" style="width:40%;">
<p>To check this is installed run:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb7-1"><a href="" aria-hidden="true" tabindex="-1"></a>cmake --version</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>and verify it is &gt;= 3.1.</p>
</div></div>
</div>

<aside><div>
<p>Check that gcc version is &gt;= 9</p>
</div></aside></section>
<section id="fortran" class="slide level2">
<h2>Fortran</h2>
<p>The file <code>hello_fortran.f90</code> contains a program to take an input array and call a subroutine to multiply it by two before printing the result.</p>
<p>The subroutine is contained in a separate module <code>math_mod.f90</code>, however.</p>
<div class="fragment">
<p>We can compile both of these to produce <code>.o</code> object files and a <code>.mod</code> module files using:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb8-1"><a href="" aria-hidden="true" tabindex="-1"></a>gfortran -c math_mod.f90 hello_fortran.f90</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment">
<p>We then link these together into an executable <code>ftn_prog</code> using:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb9-1"><a href="" aria-hidden="true" tabindex="-1"></a>gfortran -o ftn_prog hello_fortran.o math_mod.o</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment">
<p>Running this as:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb10-1"><a href="" aria-hidden="true" tabindex="-1"></a>./ftn_prog</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>should produce the output</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb11-1"><a href="" aria-hidden="true" tabindex="-1"></a> Hello, World!</span>
<span id="cb11-2"><a href="" aria-hidden="true" tabindex="-1"></a> Input:     0.00000000        1.00000000        2.00000000        3.00000000        4.00000000</span>
<span id="cb11-3"><a href="" aria-hidden="true" tabindex="-1"></a> Output:    0.00000000        2.00000000        4.00000000        6.00000000        8.00000000</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<!-- =============================================================================== -->
<aside><div>
<p>object files contain code run by the machine, and module files contain interfaces to modules.</p>
</div></aside></section></section>
<section>
<section id="motivation" class="title-slide slide level1 center">
<h1>Motivation</h1>
<!--
## Climate Models

Climate models are large, complex, many-part systems.\

![]( images/Climate_Models.svg )
-->
</section>
<section id="machine-learning-in-science" class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Machine Learning in Science</h2>
<p>We typically think of Deep Learning as an end-to-end process;<br>
a black box with an input and an output<sup>1</sup>.</p>
<p><img data-src="images/neural_net_3b1b.jpeg" class="absolute" style="border-radius: 50%;top: 39%; left: 35%; width: 30%; height: 32%; "></p>
<p><img data-src="images/pikachu.png" class="absolute" style="top: 37.5%; left: 5.5%; width: 25%; "> <span class="absolute" style="text-align:center;top: 32.5%; left: 4%; width: 25%; ">Who’s that Pokémon?</span></p>
<p><span class="absolute" style="top: 30%; right: 8.5%; width: 25%; "><span class="math display">\[\begin{bmatrix}\vdots\\a_{23}\\a_{24}\\a_{25}\\a_{26}\\a_{27}\\\vdots\\\end{bmatrix}=\begin{bmatrix}\vdots\\0\\0\\1\\0\\0\\\vdots\\\end{bmatrix}\]</span></span> <span class="absolute" style="text-align:center;top: 27.5%; right: 8.5%; width: 25%; ">It’s Pikachu!</span></p>
<div class="attribution">
<p>Neural Net by <a href="https://www.3blue1brown.com/topics/neural-networks">3Blue1Brown</a> under <a href="https://www.gov.uk/guidance/exceptions-to-copyright"><em>fair dealing</em></a>.<br>
Pikachu © <em>The Pokemon Company</em>, used under <a href="https://www.gov.uk/guidance/exceptions-to-copyright"><em>fair dealing</em></a>.</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn1"><p>And some models like GraphCast, FourCastNet, and Pangu operate on this principle</p></li></ol></aside></section>
<section id="machine-learning-in-science-1" class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Machine Learning in Science</h2>
<p><img data-src="images/Climate_Models.svg"></p>
<p><img data-src="images/neural_net_3b1b.jpeg" class="absolute" style="border-radius: 50%;left: 56%; bottom: 7%; width: 25%; height: 21%; "></p>
<div class="attribution">
<p>Neural Net by <a href="https://www.3blue1brown.com/topics/neural-networks">3Blue1Brown</a> under <a href="https://www.gov.uk/guidance/exceptions-to-copyright"><em>fair dealing</em></a>.<br>
Pikachu © <em>The Pokemon Company</em>, used under <a href="https://www.gov.uk/guidance/exceptions-to-copyright"><em>fair dealing</em></a>.</p>
</div>
</section>
<section id="challenges" class="slide level2">
<h2>Challenges</h2>
<ul>
<li>Reproducibility
<ul>
<li>Ensure net functions the same in-situ</li>
</ul></li>
<li>Re-usability
<ul>
<li>Make ML parameterisations available to many models</li>
<li>Facilitate easy re-training/adaptation</li>
</ul></li>
<li>Language Interoperation</li>
</ul>
</section>
<section id="language-interoperation" class="slide level2">
<h2>Language interoperation</h2>
<p>Many large scientific models are written in Fortran (or C, or C++).<br>
Much machine learning is conducted in Python.</p>
<p><img data-src="https://upload.wikimedia.org/wikipedia/commons/5/55/Mathematical_Bridge_tangents.jpg" class="absolute" style="border-radius: 50%;top: 27%; left: 30%; width: 40%; "></p>
<p><img data-src="https://www.python.org/static/community_logos/python-logo-generic.svg" class="absolute" style="top: 40%; left: 0px; width: 30%; "></p>
<p><img data-src="https://raw.githubusercontent.com/pytorch/pytorch/main/docs/source/_static/img/pytorch-logo-dark.png" class="absolute" style="background-image: radial-gradient(gray 0%, #03334E 75%);top: 55%; left: 5%; width: 20%; "></p>
<p><img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/696px-TensorFlowLogo.svg.png?20180105010857" class="absolute" style="top: 65%; left: 7.5%; width: 15%; "></p>
<p><img data-src="https://raw.githubusercontent.com/fortran-lang/fortran-lang.org/bbdc33ec7bfc06fa6111093ae9712a7f7837b555/assets/img/fortran-logo.svg" class="absolute" style="top: 40%; right: 10%; width: 10%; "></p>
<p><img data-src="https://www.metoffice.gov.uk/binaries/content/gallery/metofficegovuk/images/about-us/website/mo_master_for_dark_backg_rbg.png" class="absolute" style="top: 55%; right: 0%; height: 10%; "></p>
<p><img data-src="https://climate.copernicus.eu/sites/default/files/custom-uploads/branding/ECMWF_Master_Logo_RGB_nostrap.png" class="absolute" style="top: 64.5%; left: 70%; height: 5%; "></p>
<p><img data-src="images/ICON.png" class="absolute" style="border-radius: 5%;bottom: 14.5%; right: 0px; width: 10%; "></p>
<p><img data-src="images/DWD.jpg" class="absolute" style="border-radius: 20%;bottom: 19.5%; right: 2%; width: 6%; "></p>
<p><img data-src="https://www2.mmm.ucar.edu/wrf/users/images/wrf_logo.jpg" class="absolute" style="bottom: 14.5%; right: 12.75%; width: 7%; "></p>
<p><img data-src="https://avatars.githubusercontent.com/u/33552285?s=200&amp;v=4.png" class="absolute" style="left: 70%; bottom: 14.5%; width: 7%; "></p>
<!--
::: {.fragment .fade-in-then-out}
![]( ../images/Fortran_TIOBE.jpg ){.absolute top=25% width=100%}
:::
-->
<div class="attribution">
<p><a href="https://en.wikipedia.org/wiki/Mathematical_Bridge">Mathematical Bridge</a> by <a href="https://commons.wikimedia.org/wiki/User:Cmglee">cmglee</a> used under <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA 3.0</a><br>
PyTorch, the PyTorch logo and any related marks are <a href="https://www.linuxfoundation.org/legal/trademark-usage">trademarks of The Linux Foundation</a>.”<br>
TensorFlow, the TensorFlow logo and any related marks are trademarks of Google Inc.</p>
</div>
</section>
<section id="efficiency" class="slide level2 smaller" data-auto-animate="true,">
<h2 data-id="quarto-animate-title">Efficiency</h2>
<p>We consider 2 types:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p>Computational</p>
<p><img data-src="https://www.svgrepo.com/show/521584/cpu.svg" style="filter: invert(100%);width:15.0%"> <img data-src="https://www.svgrepo.com/show/42898/ram-memory.svg" style="filter: invert(100%);width:15.0%"> <img data-src="https://www.svgrepo.com/show/325133/electronics-transister.svg" style="filter: invert(100%);width:15.0%"> <img data-src="https://www.svgrepo.com/show/479706/stopwatch.svg" style="filter: invert(100%);width:15.0%"></p>
</div><div class="column">
<p>Developer</p>
<p><img data-src="https://www.svgrepo.com/show/308093/software-developer-work-on-computer-programmer-coder.svg" style="filter: invert(100%);width:15.0%"> <img data-src="https://www.svgrepo.com/show/67720/brain-speech-bubble.svg" style="filter: invert(100%);width:15.0%"> <img data-src="https://www.svgrepo.com/show/490654/coffee-maker.svg" style="filter: invert(100%);width:15.0%"> <img data-src="https://www.svgrepo.com/show/479706/stopwatch.svg" style="filter: invert(100%);width:15.0%"></p>
</div></div>
<p>Both affect ‘time-to-science’.</p>
<ul>
<li>Don’t rewrite nets after you have already trained them.</li>
<li>Not all scientists are computer scientists.
<ul>
<li>Software should be simple to learn and deploy.</li>
<li>May not have access to extensive software support.</li>
</ul></li>
<li>HPC environments want minimal additional dependencies.</li>
<li>Needs to be as efficient as possible.</li>
</ul>
<!-- =============================================================================== -->
</section></section>
<section>
<section id="how-it-works" class="title-slide slide level1 center">
<h1>How it Works</h1>
<!--
## (Py)Torch

::::{.columns}
:::{.column width=50%}
#### Torch

- an open-source deep learning framework
- developed at EPFL in Switzerland
- written in C with a LUA interface

![](images/Torch_logo.png)

:::
:::{.column width=50%}
#### PyTorch

- an open-source deep-learning framework
- developed by Meta AI, now part of the Linux Foundation
- written in C++ with a Python interface
- port of Torch (ATen), but also includes Caffe2 etc.

![]( https://raw.githubusercontent.com/pytorch/pytorch/main/docs/source/_static/img/pytorch-logo-dark.png ){style="background-image: radial-gradient(gray 0%, #03334E 75%);"}
:::
::::

:::{.attribution}
Torch and PyTorch logos under Creative Commons
:::
-->
<!--
## (Py)Torch

#### Automatic Differentiation

- Symbolic Differentiation
- Numerical Differentiation
- Automatic Differentiation
-->
<!--
## TorchScript and libtorch

PyTorch provides a (pythonic-ish) C++ interface to the underlying C++ codes.

This is accessible through libtorch
-->
</section>
<section id="ftorch" class="slide level2">
<h2>FTorch</h2>
<p><img data-src="https://raw.githubusercontent.com/fortran-lang/fortran-lang.org/bbdc33ec7bfc06fa6111093ae9712a7f7837b555/assets/img/fortran-logo.svg" class="absolute" style="top: 10%; right: 12.5%; width: 15%; "></p>
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="top: 20%; right: 30%; width: 35%; height: 20%; "></p>
<p><img data-src="https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/community/logos/python-logo-only.png" class="absolute" style="top: 40%; left: 30%; height: 20%; "></p>
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="transform: rotate(270deg);top: 70%; left: 30%; width: 18%; height: 10%; "></p>
<p><img data-src="https://www.pngall.com/wp-content/uploads/5/Open-Box-PNG-Clipart.png" class="absolute" style="top: 18%; left: 0%; height: 22%; "></p>
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="transform: rotate(270deg);top: 33%; left: 14%; width: 10%; height: 25%; "></p>
<div class="absolute" style="text-align: center; color: black;top: 27%; left: 6.5%; ">
<p>Python<br>
env</p>
</div>
<div class="absolute" style="text-align: center;top: 44%; left: 44%; ">
<p>Python<br>
runtime</p>
</div>
<p><img data-src="https://raw.githubusercontent.com/pytorch/pytorch/main/docs/source/_static/img/pytorch-logo-dark.png" class="absolute" style="background-image: radial-gradient(gray 0%, #03334E 75%);bottom: 10.5%; right: 6%; height: 13%; "></p>
<div class="fragment fade-in-then-semi-out">
<p><img data-src="https://imgs.xkcd.com/comics/python_environment_2x.png" class="absolute" style="left: 0%; bottom: 13%; height: 70%; "></p>
</div>
<div class="attribution">
<p><a href="https://xkcd.com/1987/">xkcd #1987</a> by Randall Munroe, used under <a href="https://creativecommons.org/licenses/by-nc/2.5/">CC BY-NC 2.5</a></p>
</div>
<div class="fragment fade-in">
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="transform: scaleY(-1) rotate(130deg); filter:hue-rotate(150deg);top: 37%; left: 78%; width: 35%; height: 20%; "></p>
</div>
</section>
<section id="libtorch-and-ftorch" class="slide level2">
<h2>libtorch and FTorch</h2>
<ul>
<li>libtorch is a C++ library providing an interface into the underlying PyTorch</li>
<li>FTorch binds to this using the <code>iso_c_binding</code> module (intrinsic since 2003).</li>
<li>We utilise shared memory (on CPU) reducing data transfer overheads</li>
</ul>
<!-- =============================================================================== -->
</section></section>
<section>
<section id="installing-ftorch" class="title-slide slide level1 center">
<h1>Installing FTorch</h1>
<!--

## Clone the git repository

::::{.columns}
:::{.column width=50%}
FTorch is available from GitHub:\
[github.com/Cambridge-ICCS/FTorch](https://github.com/Cambridge-ICCS/FTorch)

::: {style="text-align: center"}

:::

:::
:::{.column width=50%}
With supporting documentation at:\
[cambridge-iccs.github.io/FTorch/](https://cambridge-iccs.github.io/FTorch/)

::: {style="text-align: center"}

:::

:::
::::

To get a copy of FTorch on your system run:
```default
git clone https://github.com/Cambridge-ICCS/FTorch.git
```
which will create a directory `FTorch/` with the contents.


## Get Libtorch (optional)

Libtorch is available from the [PyTorch homepage](https://pytorch.org/):

![](images/libtorch.jpg){width=75%}

We _can_ use the version of libtorch that comes with pip-installed PyTorch (see docs).\
Standalone libtorch removes Python and aids reproducibility, especially
on HPC systems.

:::{.aside}
Notes: Need GCC>9 and GLIBC 2.29 for CXX11.\
Whilst most features should be compatible between PyTorch and libtorch versions, keep this in mind if issues occur.
:::

-->
</section>
<section id="ftorch-source-code" class="slide level2">
<h2>FTorch source code</h2>
<p>The source code for FTorch is contained in the <code>src/</code> directory. This contains:</p>
<ul>
<li><code>ctorch.cpp</code> - Bindings to the libtorch C++ API.</li>
<li><code>ctorch.h</code> - C header file to bind to from Fortran.</li>
<li><code>ftorch.F90</code> - the Fortran routines we will be calling.</li>
</ul>
<p><br>
</p>
<p>These are compiled, linked together, and installed using CMake.</p>
<ul>
<li>Simplify build process for users.</li>
<li>Accomodate different machines and setups.</li>
<li>Configured in the <code>CMakeLists.txt</code> file.</li>
</ul>
</section>
<section id="build-ftorch" class="slide level2">
<h2>Build FTorch</h2>
<p>This is all handled by the <code>build_FTorch.sh</code> script in the Codespace.</p>
<p><br>
</p>
<p>To keep things clean we will do all of our building from a self-contained <code>build/</code> directory.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb12-1"><a href="" aria-hidden="true" tabindex="-1"></a>cd FTorch/src/</span>
<span id="cb12-2"><a href="" aria-hidden="true" tabindex="-1"></a>mkdir build</span>
<span id="cb12-3"><a href="" aria-hidden="true" tabindex="-1"></a>cd build</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can now execute CMake to build here using the code in the above directory:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb13-1"><a href="" aria-hidden="true" tabindex="-1"></a>cmake .. -DCMAKE_BUILD_TYPE=Release</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="build-ftorch---details" class="slide level2">
<h2>Build FTorch - details</h2>
<p>In reality we often need to specify a number of additional options:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb14-1"><a href="" aria-hidden="true" tabindex="-1"></a>cmake .. -DCMAKE_BUILD_TYPE=Release \</span>
<span id="cb14-2"><a href="" aria-hidden="true" tabindex="-1"></a>&gt;        -DCMAKE_Fortran_COMPILER=gfortran \</span>
<span id="cb14-3"><a href="" aria-hidden="true" tabindex="-1"></a>&gt;        -DCMAKE_C_COMPILER=gcc \</span>
<span id="cb14-4"><a href="" aria-hidden="true" tabindex="-1"></a>&gt;        -DCMAKE_CXX_COMPILER=g++ \</span>
<span id="cb14-5"><a href="" aria-hidden="true" tabindex="-1"></a>&gt;        -DCMAKE_PREFIX_PATH=&lt;path/to/libtorch/&gt; \</span>
<span id="cb14-6"><a href="" aria-hidden="true" tabindex="-1"></a>&gt;        -DCMAKE_INSTALL_PREFIX=&lt;path/to/install/ftorch/&gt; \</span>
<span id="cb14-7"><a href="" aria-hidden="true" tabindex="-1"></a>&gt;        -DCMAKE_GPU_DEVICE=&lt;NONE|CUDA|XPU|MPS&gt; \</span>
<span id="cb14-8"><a href="" aria-hidden="true" tabindex="-1"></a>&gt;        ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br>
</p>
<p>Notes:</p>
<ul>
<li>The Fortran compiler should match that being used to build your code.</li>
<li>We need gcc &gt;= 9.</li>
<li>Set build type to <code>Debug</code> for debugging with <code>-g</code>.</li>
<li>Prefix path is wherever libtorch is on your system.</li>
<li>Install prefix can be set to anywhere. Defaults may require root/admin access.</li>
</ul>
</section>
<section id="build-ftorch---details-1" class="slide level2">
<h2>Build FTorch - details</h2>
<p>Assuming everything proceeds successfully CMake will generate a <code>Makefile</code> for us.</p>
<p><br>
</p>
<p>We can run this locally using<sup>1</sup>:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb15-1"><a href="" aria-hidden="true" tabindex="-1"></a>cmake --build .</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If we specified a particular location to install FTorch we can do this by running<sup>2</sup>:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb16-1"><a href="" aria-hidden="true" tabindex="-1"></a>cmake --install .</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br>
</p>
<p>The above two commands can be combined into a single option using:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb17-1"><a href="" aria-hidden="true" tabindex="-1"></a>cmake --build . --target install</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside><ol class="aside-footnotes"><li id="fn2"><p>Alternatively, or for CMake&lt;3.15 we can use the system <code>make</code> command.</p></li><li id="fn3"><p>Alternatively, or for CMake&lt;3.15 we can use the system <code>make install</code> command.</p></li></ol></aside></section>
<section id="build-ftorch---details-2" class="slide level2">
<h2>Build FTorch - details</h2>
<p>Installation will place files in <code>CMAKE_INSTALL_PREFIX/</code>:</p>
<ul>
<li><code>include/</code> contains header and mod files.</li>
<li><code>lib/</code> contains cmake and library files.
<ul>
<li>This could be called <code>lib64/</code> on some systems.</li>
<li>UNIX will use <code>.so</code> files whilst Windows has <code>.dll</code> files.</li>
</ul></li>
</ul>
<!-- =============================================================================== -->
</section></section>
<section>
<section id="exercises" class="title-slide slide level1 center">
<h1>Exercises</h1>

</section>
<section id="exercise-1" class="slide level2">
<h2>Exercise 1</h2>
<p>Now that we have FTorch installed on the system we can move to writing code that uses it, needing only to link to our installation at compile and runtime.</p>
<p><br>
</p>
<p>We will start of with a basic example showing how to couple code in Exercise 1:</p>
<ol type="1">
<li>Design and train a PyTorch model.</li>
<li>Save PyTorch model to TorchScript.</li>
<li>Write Fortran using FTorch to call saved model.</li>
<li>Compile and run code, linking to FTorch.</li>
</ol>
</section>
<section id="pytorch" class="slide level2">
<h2>PyTorch</h2>
<p>Examine <code>exercises/exercise_01/simplenet.py</code>.</p>
<p><br>
</p>
<p>This contains a contrived PyTorch model with a single <code>nn.Linear</code> layer that will multiply the input by two.</p>
<p><br>
</p>
<p>With our virtual environment active we can test this by running the code with<sup>1</sup>:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb18-1"><a href="" aria-hidden="true" tabindex="-1"></a>python3 simplenet.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Input:  tensor([0., 1., 2., 3., 4.])
Output: tensor([0., 2., 4., 6., 8.])</code></pre>
<aside><ol class="aside-footnotes"><li id="fn4"><p>This will run the <code>if __name__ == "__main__":</code> section at the bottom of the file.</p></li></ol></aside></section>
<section id="offline-training-with-ftorch" class="slide level2">
<h2>Offline training with FTorch</h2>
<p><img data-src="https://cambridge-iccs.github.io/FTorch/page/offline.png" class="absolute" style="top: 35%; left: 20%; width: 60%; "></p>
</section>
<section id="saving-to-torchscript" class="slide level2">
<h2>Saving to TorchScript</h2>
<p>To use the net from Fortran we need to save it to TorchScript.</p>
<p><br>
</p>
<p>FTorch comes with a handy utility <code>pt2ts.py</code> to help with this located at<br>
<code>FTorch/utils/pt2ts.py</code>.</p>
<p><br>
</p>
<p>We will now copy this across to <code>exercise_01/</code>, modify it, and run it to save our code to TorchScript.</p>
</section>
<section id="saving-to-torchscript-1" class="slide level2">
<h2>Saving to TorchScript</h2>
<p>Notes:</p>
<ul>
<li>There are handy <code>TODO</code> comments where you need to adapt the code.</li>
<li><code>pt2ts.py</code> expects an <code>nn.Module</code> subclass with a <code>forward()</code> method.</li>
<li>there are two options to save:
<ul>
<li><a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">tracing</a> using <code>torch.jit.trace()</code><br>
This passes a dummy tensor throgh the model recording operations.<br>
It is the simplest approach.</li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.jit.script.html">scripting</a> using <code>torch.jit.script()</code><br>
This converts Python code directly to TorchScript.<br>
It is more complicated, but neccessary for advanced features and/or control operations.</li>
</ul></li>
<li>A summary of the TorchScript model can be printed from Python.</li>
</ul>

<aside><div>
<p>See <a href="https://pytorch.org/docs/stable/jit_language_reference.html#language-reference">TorchScript reference</a> for feature compatibility.</p>
</div></aside></section>
<section id="offline-training-with-ftorch-1" class="slide level2">
<h2>Offline training with FTorch</h2>
<p><img data-src="https://cambridge-iccs.github.io/FTorch/page/offline.png" class="absolute" style="top: 35%; left: 20%; width: 60%; "></p>
</section>
<section id="calling-from-fortran" class="slide level2">
<h2>Calling from Fortran</h2>
<p>We are now in a state to use our saved TorchScript model from within Fortran.</p>
<p><code>exercises/exercise_01/simplenet_fortran.f90</code> contains a skeleton code with a Fortran arrays to hold input data for the net, and the results returned.</p>
<p><br>
</p>
<p>We will modify it to create the neccessary data structures and load and call the net.</p>
<ul>
<li>Import the <code>ftorch</code> module.</li>
<li>Create <code>torch_tensors</code> and a <code>torch_model</code> to hold the data and net.</li>
<li>Map Fortran data from arrays to the <code>torch_tensors</code>.</li>
<li>Call <code>torch_model_forward</code> to run the net.</li>
<li>Clean up.</li>
</ul>
</section>
<section id="calling-from-fortran-1" class="slide level2">
<h2>Calling from Fortran</h2>
<p>Notes:</p>
<ul>
<li>See the solution file <code>simplenet_fortran_sol.f90</code> for an ideal code.</li>
<li>for more information on the subroutines and API see the <a href="https://cambridge-iccs.github.io/FTorch/lists/procedures.html">online API documentation</a></li>
</ul>
</section>
<section id="building-the-code" class="slide level2">
<h2>Building the code</h2>
<p>Once we have modified the Fortran we need to compile the code and link it to FTorch.</p>
<p>For convenience, this can be done in the codespace by simply running <code>make</code> in the <code>exercise_01/</code> subdirectory.</p>
</section>
<section id="running-the-code" class="slide level2">
<h2>Running the code</h2>
<p>To run the code we can use the generated executable:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb20-1"><a href="" aria-hidden="true" tabindex="-1"></a>./simplenet_fortran</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>   0.00000000       2.00000000       4.00000000       6.00000000       8.00000000</code></pre>
<!-- =============================================================================== -->
</section>
<section id="exercise-2-larger-code-considerations" class="slide level2">
<h2>Exercise 2: Larger code considerations</h2>
<p>What we have considered so far is a simple contrived example designed to teach the basics.</p>
<p>However, in reality the codes we will be using are more complex, and full of terrors.</p>
<ul>
<li>We will be calling the net repeatedly over the course of many iterations.</li>
<li>Reading in the net and weights from file is expensive.
<ul>
<li>Don’t do this at every step!</li>
</ul></li>
</ul>
</section>
<section id="exercise-2-larger-code-considerations-1" class="slide level2">
<h2>Exercise 2: Larger code considerations</h2>
<p>In exercise 2 we will look at an example of how to ideally structure a slightly more complex code setup. For those familiar with climate models this may be nothing new. We make use of the traditional separation into subroutines for:</p>
<ol type="1">
<li>Initialisation</li>
<li>Updating</li>
<li>Finalisation</li>
</ol>
</section>
<section id="exercise-2" class="slide level2">
<h2>Exercise 2</h2>
<p>Navigate to the <code>exercises/exercise_02/</code> directory.</p>
<p>Here you will see two code directories, <code>good/</code> and <code>bad/</code>.</p>
<p>Both perform the same operation:</p>
<ul>
<li>Running the simplenet from example 1 10,000 times.</li>
<li>Increment the input vector at each step.</li>
<li>Accumulate the sum of the output vector.</li>
</ul>
</section>
<section id="exercise-2-1" class="slide level2">
<h2>Exercise 2</h2>
<p>The exercise is the same for both folders:</p>
<ul>
<li>Run the pre-prepared <code>pt2ts.py</code> script to save the net.</li>
<li>Inspect the code to see how it works:
<ul>
<li>Both have a main program in <code>simplenet_fortran.f90</code>.</li>
<li>Both have FTorch code extracted to a module <code>fortran_ml_mod.f90</code>.
<ul>
<li><code>bad</code> is in a single routine.</li>
<li><code>good</code> is split into init, iter, and finalise.</li>
</ul></li>
</ul></li>
<li>Modify the Makefile to link to FTorch and build the codes.</li>
<li>Time the codes and observe the difference.</li>
</ul>
</section>
<section id="exercise-2---solution" class="slide level2">
<h2>Exercise 2 - solution</h2>
<p>For a complete version of the example, see the <a href="https://github.com/Cambridge-ICCS/FTorch/tree/main/examples/5_Looping">Looping example</a>.</p>
</section>
<section id="exercise-3-automatic-differentiation" class="slide level2">
<h2>Exercise 3: automatic differentiation</h2>
<p>PyTorch has a powerful automatic differentiation engine called <code>autograd</code> that can be used to compute derivatives of expressions involving tensors.</p>
<p><br>
</p>
<p>We recently exposed this functionality in FTorch, allowing you to do this in Fortran, too. This is a key step facilitating online training in FTorch.</p>
<p><br>
</p>
<p>In this exercise, we walk through differentiating the mathematical expression <span class="math display">\[Q = 3 (a^3 - b^2/3)\]</span> using both PyTorch and FTorch.</p>
</section>
<section id="multiple-inputs-and-outputs" class="slide level2">
<h2>Multiple inputs and outputs</h2>
<p>Supply as an array of tensors, innit.</p>
<ul>
<li>For more details see the <a href="https://github.com/Cambridge-ICCS/FTorch/tree/main/examples/6_MultiIO">MultiIO Example</a>.</li>
</ul>
</section>
<section id="gpu-acceleration" class="slide level2">
<h2>GPU Acceleration</h2>
<ul>
<li>FTorch automatically has access to GPU acceleration through the PyTorch backend.</li>
<li>When running <code>pt2ts.py</code>, save the model on GPU.
<ul>
<li>Guidance provided in the file.</li>
</ul></li>
<li>When creating <code>torch_tensor</code>s set the device to <code>torch_kCUDA</code> instead of <code>torch_kCPU</code>.<sup>1</sup></li>
<li>To target a specific device supply the <code>device_index</code> argument.</li>
<li>CPU-GPU cannot avoid data transfer. Use <code>MPI_GATHER()</code> to reduce.</li>
<li>Use <code>torch_tensor_to</code> to transfer tensors between devices (and data types).</li>
<li>For more details see:
<ul>
<li>the <a href="https://cambridge-iccs.github.io/FTorch/page/gpu.html">online documentation</a></li>
<li>the <a href="https://github.com/Cambridge-ICCS/FTorch/tree/main/examples/6_MultiGPU">GPU Example</a></li>
</ul></li>
</ul>
<!-- =============================================================================== -->
<aside><ol class="aside-footnotes"><li id="fn5"><p>We can also use Intel XPU and AppleSilicon MPS, and are investigating AMD.</p></li></ol></aside></section></section>
<section>
<section id="applications-and-case-studies" class="title-slide slide level1 center">
<h1>Applications and Case Studies</h1>

</section>
<section id="mima---proof-of-concept" class="slide level2">
<h2>MiMA - proof of concept</h2>
<ul>
<li>The origins of FTorch.
<ul>
<li>Emulation of existing parameterisation.</li>
<li>Coupled to an atmospheric model using <code>forpy</code> in <span class="citation" data-cites="espinosa2022machine">Espinosa et al. (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span>.<sup>1</sup></li>
<li>Prohibitively slow and hard to implement.</li>
<li>Asked for a faster, user-friendly implementation that can be used in future studies.</li>
</ul></li>
</ul>
<p><br>
</p>
<ul>
<li>Follow up paper using FTorch: <em>Uncertainty Quantification of a Machine Learning Subgrid-Scale Parameterization for Atmospheric Gravity Waves</em> <span class="citation" data-cites="mansfield2024uncertainty">(<a href="#/references" role="doc-biblioref" onclick="">Mansfield and Sheshadri 2024</a>)</span>.
<ul>
<li>“Identical” offline networks have very different behaviours when deployed online.</li>
</ul></li>
</ul>

<aside><div>
<p>Model of an idealised Moist Atmosphere online at <a href="https://github.com/DataWaveProject/MiMA-machine-learning"><i class="fa-brands fa-github" aria-label="github"></i>/DataWaveProject/MiMA-machine-learning</a>.</p>
</div><ol class="aside-footnotes"><li id="fn6"><p>Originally written in TensorFlow…</p></li></ol></aside></section>
<section id="icon" class="slide level2">
<h2>ICON</h2>
<ul>
<li>Icosahedral Nonhydrostatic Weather and Climate Model.
<ul>
<li>Developed by DKRZ (Deutsches Klimarechenzentrum).</li>
<li>Used by the DWD and Meteo-Swiss.</li>
</ul></li>
</ul>
<div class="columns">
<div class="column" style="width:75%;">
<ul>
<li><em>Interpretable multiscale Machine Learning-Based Parameterizations of Convection for ICON</em> <span class="citation" data-cites="heuer2023interpretable">(<a href="#/references" role="doc-biblioref" onclick="">Heuer et al. 2023</a>)</span>.<sup>1</sup>
<ul>
<li>Train U-Net convection scheme on high-res simulation.</li>
<li>Deploy in ICON via FTorch coupling.</li>
<li>Evaluate physical realism (causality) using SHAP values.</li>
<li>Online stability improved when non-causal relations are eliminated from the net.</li>
</ul></li>
</ul>
</div></div>
<p><img data-src="images/Heuer_SHAP.jpg" class="absolute" style="top: 45%; right: 0px; width: 27%; "></p>
<p><img data-src="images/ICON.png" class="absolute" style="border-radius: 5%;top: 15%; right: 0px; width: 27%; "></p>

<aside><div>
<p>Running on JUWELS at the Jülich Supercomputing Centre; ICON Model is now available at <a href="https://gitlab.dkrz.de/icon/icon-model">gitlab.dkrz.de/icon/icon-model</a>.<br>
</p>
</div><ol class="aside-footnotes"><li id="fn7"><p>Work without direct involvement of ICCS - success on ‘ease of use’ of FTorch</p></li></ol></aside></section>
<section id="cesm---bias-correction" class="slide level2">
<h2>CESM - Bias Correction</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Work by Will Chapman of NCAR/M2LInES.</p>
<ul>
<li><p>As representations of physics models have inherent, sometimes systematic, biases.</p></li>
<li><p>Run CESM for 9 years relaxing hourly to ERA5 observation (data assimilation).</p></li>
<li><p>Train CNN to predict anomaly increment at each level.</p>
<ul>
<li>targeting just the MJO region.</li>
<li>targeting globally.</li>
</ul></li>
<li><p>Apply online as part of predictive runs.</p></li>
</ul>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Will_Champan_CNN_SLP_bias.jpg" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Will_Champan_CNN_precip_bias.jpg" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
</figure>
</div>
</div></div>
</section>
<section id="cesm-coupling" class="slide level2">
<h2>CESM coupling</h2>
<ul>
<li>The Community Earth System Model.</li>
<li>Part of <a href="https://wcrp-cmip.org/">CMIP</a> (Coupled Model Intercomparison Project).</li>
<li>Make it easy for users.
<ul>
<li>FTorch integrated into the build system (CIME).
<ul>
<li><a href="https://github.com/Cambridge-ICCS/cime_je"><i class="fa-brands fa-github" aria-label="github"></i>/Cambridge-ICCS/cime_je</a></li>
</ul></li>
<li><code>libtorch</code> is included on the software stack on Derecho.
<ul>
<li>Improves reproducibility.</li>
</ul></li>
</ul></li>
</ul>
<p><img data-src="https://www.hpcwire.com/wp-content/uploads/2022/03/derecho-ncar-render.png" class="absolute" style="top: 15%; right: 0%; height: 20%; "></p>

<div class="attribution">
<p>Derecho by NCAR</p>
</div>
<aside><div>
<p>Work done with Will Chapman and Jim Edwards of NCAR.<br>
CIME with FTorch is available with instructions <a href="https://github.com/Cambridge-ICCS/cime_je"><i class="fa-brands fa-github" aria-label="github"></i>/Cambridge-ICCS/cime_je</a>.</p>
</div></aside></section>
<section id="ongoing-and-future-work" class="slide level2 smaller">
<h2>Ongoing and future Work</h2>
<ul>
<li>UKCA (United Kingdom Chemistry and Aerosols) case study.
<ul>
<li><em>See Joe’s talk in the Weather and Climate session on Wednesday!</em></li>
</ul></li>
<li>Online training</li>
<li>AMD GPU device support</li>
<li>Benchmarking against other solutions
<ul>
<li>Benchmarking “ease of use” is hard</li>
</ul></li>
</ul>
<!-- =============================================================================== -->
</section>
<section id="thanks-for-listening" class="slide level2 smaller">
<h2>Thanks for Listening</h2>
<p>For more information please speak to us afterwards, or drop us a message.</p>
<p><img data-src="https://iccs.cam.ac.uk/sites/default/files/logo2_2.png" class="absolute" style="width: 20%; height: 30%; object-fit: cover; object-position: 0 0;top: 25%; right: 0%; "></p>
<p>The ICCS received support from <img data-src="images/schmidt_science.png" style="margin: 0; vertical-align: -2%;height:2.4em"></p>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-espinosa2022machine" class="csl-entry" role="listitem">
Espinosa, Zachary I, Aditi Sheshadri, Gerald R Cain, Edwin P Gerber, and Kevin J DallaSanta. 2022. <span>“Machine Learning Gravity Wave Parameterization Generalizes to Capture the QBO and Response to Increased CO2.”</span> <em>Geophysical Research Letters</em> 49 (8): e2022GL098174.
</div>
<div id="ref-heuer2023interpretable" class="csl-entry" role="listitem">
Heuer, Helge, Mierk Schwabe, Pierre Gentine, Marco A Giorgetta, and Veronika Eyring. 2023. <span>“Interpretable Multiscale Machine Learning-Based Parameterizations of Convection for ICON.”</span> <em>arXiv Preprint arXiv:2311.03251</em>.
</div>
<div id="ref-mansfield2024uncertainty" class="csl-entry" role="listitem">
Mansfield, Laura A, and Aditi Sheshadri. 2024. <span>“Uncertainty Quantification of a Machine Learning Subgrid-Scale Parameterization for Atmospheric Gravity Waves.”</span> <em>Authorea Preprints</em>.
</div>
</div>

</section></section>

    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="https://iccs.cam.ac.uk/sites/default/files/iccs_ucam_combined_reverse_colour.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/reveal-attribution/attribution.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="ftorch_workshop_slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealAttribution, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>